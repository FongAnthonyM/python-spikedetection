{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"artifact_pipeline.py\n",
    "A pipeline for removing artifact.\n",
    "\"\"\"\n",
    "\n",
    "# Imports #\n",
    "# Standard Libraries #\n",
    "import cProfile\n",
    "import datetime\n",
    "import importlib\n",
    "import io\n",
    "import os\n",
    "import pathlib\n",
    "import pstats\n",
    "from pstats import Stats, f8, func_std_string\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Third-Party Packages #\n",
    "from fooof.sim.gen import gen_aperiodic\n",
    "from fooof import FOOOF, FOOOFGroup\n",
    "import hdf5objects\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import hdf5objects.dataframes as hdframes\n",
    "\n",
    "# Local Packages #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Definitions #\n",
    "# Classes #\n",
    "class R2Map(hdf5objects.basehdf5.BaseHDF5Map):\n",
    "    default_attribute_names = {\"file_type\": \"FileType\",\n",
    "                               \"file_version\": \"FileVersion\",\n",
    "                               \"subject_id\": \"subject_id\",\n",
    "                               \"start\": \"start\",\n",
    "                               \"end\": \"end\",\n",
    "                               \"window_size\": \"window_size\"}\n",
    "    default_map_names = {\"data\": \"data\"}\n",
    "    default_maps = {\"data\": hdf5objects.datasets.TimeSeriesMap()}\n",
    "\n",
    "\n",
    "class R2HDF5(hdf5objects.BaseHDF5):\n",
    "    FILE_TYPE = \"R2OverTime\"\n",
    "    default_map = R2Map()\n",
    "\n",
    "\n",
    "class StatsMicro(Stats):\n",
    "    def print_stats(self, *amount):\n",
    "        for filename in self.files:\n",
    "            print(filename, file=self.stream)\n",
    "        if self.files:\n",
    "            print(file=self.stream)\n",
    "        indent = \" \" * 8\n",
    "        for func in self.top_level:\n",
    "            print(indent, func_get_function_name(func), file=self.stream)\n",
    "\n",
    "        print(indent, self.total_calls, \"function calls\", end=\" \", file=self.stream)\n",
    "        if self.total_calls != self.prim_calls:\n",
    "            print(\"(%d primitive calls)\" % self.prim_calls, end=\"  \", file=self.stream)\n",
    "        print(\"in %.3f microseconds\" % (self.total_tt * 1000000), file=self.stream)\n",
    "        print(file=self.stream)\n",
    "        width, list = self.get_print_list(amount)\n",
    "        if list:\n",
    "            self.print_title()\n",
    "            for func in list:\n",
    "                self.print_line(func)\n",
    "            print(file=self.stream)\n",
    "            print(file=self.stream)\n",
    "        return self\n",
    "\n",
    "    def print_title(self):\n",
    "        print('          ncalls          tottime      percall      cumtime      percall', end=' ', file=self.stream)\n",
    "        print('filename:lineno(function)', file=self.stream)\n",
    "\n",
    "    def print_line(self, func):  # hack: should print percentages\n",
    "        cc, nc, tt, ct, callers = self.stats[func]\n",
    "        c = str(nc)\n",
    "        if nc != cc:\n",
    "            c = c + \"/\" + str(cc)\n",
    "        print(c.rjust(20), end=\" \", file=self.stream)\n",
    "        print(str(f8(tt * 1000000)).rjust(12), end=\" \", file=self.stream)\n",
    "        if nc == 0:\n",
    "            print(\" \" * 8, end=\" \", file=self.stream)\n",
    "        else:\n",
    "            print(str(f8(tt / nc * 1000000)).rjust(12), end=\" \", file=self.stream)\n",
    "        print(str(f8(ct * 1000000)).rjust(12), end=\" \", file=self.stream)\n",
    "        if cc == 0:\n",
    "            print(\" \" * 8, end=\" \", file=self.stream)\n",
    "        else:\n",
    "            print(str(f8(ct / cc * 1000000)).rjust(12), end=\" \", file=self.stream)\n",
    "        print(func_std_string(func), file=self.stream)\n",
    "\n",
    "\n",
    "# Functions #\n",
    "def closest_square(n):\n",
    "    n = int(n)\n",
    "    i = int(np.ceil(np.sqrt(n)))\n",
    "    while True:\n",
    "        if (n % i) == 0:\n",
    "            break\n",
    "        i += 1\n",
    "    assert n == (i * (n // i))\n",
    "    return i, n // i\n",
    "\n",
    "\n",
    "def get_lead_groups(el_label, el_type):\n",
    "    assert len(el_label) == len(el_type)\n",
    "\n",
    "    LEAD_NAME_NOID = np.array([''.join(map(lambda c: '' if c in '0123456789' else c, ll))\n",
    "        for ll in el_label])\n",
    "    CONTACT_IX = np.arange(len(el_label))\n",
    "    LEAD_NAME = np.unique(LEAD_NAME_NOID)\n",
    "\n",
    "    lead_group = {}\n",
    "    for l_name in LEAD_NAME:\n",
    "        lead_group[l_name] = \\\n",
    "            {'Contacts': el_label[np.flatnonzero(LEAD_NAME_NOID == l_name)],\n",
    "             'IDs': CONTACT_IX[np.flatnonzero(LEAD_NAME_NOID == l_name)],\n",
    "             'Type': np.unique(el_type[np.flatnonzero(LEAD_NAME_NOID == l_name)])}\n",
    "        assert len(lead_group[l_name]['Type']) == 1\n",
    "\n",
    "        lead_group[l_name]['Type'] = lead_group[l_name]['Type'][0]\n",
    "\n",
    "    return lead_group\n",
    "\n",
    "\n",
    "def make_bipolar(lead_group):\n",
    "    for l_name in lead_group:\n",
    "        sel_lead = lead_group[l_name]\n",
    "        n_contact = len(sel_lead['IDs'])\n",
    "        if 'grid' in sel_lead['Type']:\n",
    "            n_row, n_col = closest_square(n_contact)\n",
    "        else:\n",
    "            n_row, n_col = [n_contact, 1]\n",
    "\n",
    "        CA = np.arange(len(sel_lead['Contacts'])).reshape((n_row, n_col), order='F')\n",
    "\n",
    "        lead_group[l_name]['Contact_Pairs_ix'] = []\n",
    "\n",
    "        if n_row > 1:\n",
    "            for bp1, bp2 in zip(CA[:-1, :].flatten(), CA[1:, :].flatten()):\n",
    "                lead_group[l_name]['Contact_Pairs_ix'].append(\n",
    "                        (sel_lead['IDs'][bp1],\n",
    "                         sel_lead['IDs'][bp2]))\n",
    "\n",
    "        if n_col > 1:\n",
    "            for bp1, bp2 in zip(CA[:, :-1].flatten(), CA[:, 1:].flatten()):\n",
    "                lead_group[l_name]['Contact_Pairs_ix'].append(\n",
    "                        (sel_lead['IDs'][bp1],\n",
    "                         sel_lead['IDs'][bp2]))\n",
    "\n",
    "        \"\"\"\n",
    "        if (n_row > 1) & (n_col > 1):\n",
    "            for bp1, bp2 in zip(CA[:-1, :-1].flatten(), CA[1:, 1:].flatten()):\n",
    "                lead_group[l_name]['Contact_Pairs_ix'].append(\n",
    "                        (sel_lead['IDs'][bp1],\n",
    "                         sel_lead['IDs'][bp2]))\n",
    "        lead_group[l_name]['Contact_Pairs_ix'] = np.array(\n",
    "            lead_group[l_name]['Contact_Pairs_ix'])\n",
    "\n",
    "        lead_group[l_name]['Contact_Pairs_ix'] = \\\n",
    "            lead_group[l_name]['Contact_Pairs_ix'][\n",
    "                np.argsort(lead_group[l_name]['Contact_Pairs_ix'][:, 0])]\n",
    "        \"\"\"\n",
    "\n",
    "    return lead_group\n",
    "\n",
    "\n",
    "def make_bipolar_elecs_all(eleclabels, eleccoords):\n",
    "\n",
    "    lead_group = get_lead_groups(eleclabels[:, 1], eleclabels[:, 2])\n",
    "    lead_group = make_bipolar(lead_group)\n",
    "\n",
    "    bp_elecs_all = {\n",
    "            'IDX': [],\n",
    "            'Anode': [],\n",
    "            'Cathode': [],\n",
    "            'Lead': [],\n",
    "            'Contact': [],\n",
    "            'Contact_Abbr': [],\n",
    "            'Type': [],\n",
    "            'x': [],\n",
    "            'y': [],\n",
    "            'z': []}\n",
    "\n",
    "    for l_name in lead_group:\n",
    "        for el_ix, el_iy in lead_group[l_name]['Contact_Pairs_ix']:\n",
    "            bp_elecs_all['IDX'].append((el_ix, el_iy))\n",
    "            bp_elecs_all['Anode'].append(el_ix)\n",
    "            bp_elecs_all['Cathode'].append(el_iy)\n",
    "\n",
    "            bp_elecs_all['Lead'].append(l_name)\n",
    "            bp_elecs_all['Contact'].append('{}-{}'.format(eleclabels[el_ix, 1], eleclabels[el_iy, 1]))\n",
    "            bp_elecs_all['Contact_Abbr'].append('{}-{}'.format(eleclabels[el_ix, 0], eleclabels[el_iy, 0]))\n",
    "            bp_elecs_all['Type'].append(lead_group[l_name]['Type'])\n",
    "\n",
    "            try:\n",
    "                coord = (eleccoords[el_ix] + eleccoords[el_iy]) / 2\n",
    "            except:\n",
    "                coord = [np.nan, np.nan, np.nan]\n",
    "            bp_elecs_all['x'].append(coord[0])\n",
    "            bp_elecs_all['y'].append(coord[1])\n",
    "            bp_elecs_all['z'].append(coord[2])\n",
    "\n",
    "    bp_elecs_all = pd.DataFrame(bp_elecs_all)\n",
    "    if np.core.numeric.dtype is None:\n",
    "        importlib.reload(np.core.numeric)\n",
    "    return bp_elecs_all.sort_values(by=['Anode', 'Cathode']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_ECoG_sample(study_frame, time_start, time_end):\n",
    "    natus_data = {}\n",
    "\n",
    "    # Get the Sample Rate\n",
    "    if study_frame.validate_sample_rate():\n",
    "        natus_data['fs'] = 1024  #\n",
    "    else:\n",
    "        natus_data['fs'] = 1024\n",
    "\n",
    "    # Get the minimum number of channels present in all recordings\n",
    "    natus_data['min_valid_chan'] = min([shape[1] for shape in study_frame.get_shapes()])\n",
    "\n",
    "    # Grab segment\n",
    "    natus_data['data'], natus_data['time_start'], natus_data['time_end'] = study_frame.get_data_range_time(\n",
    "        time_start, time_end, aprox=True)\n",
    "\n",
    "    # Create a timestamp vector\n",
    "    natus_data['timestamp vector'] = study_frame.get_timestamp_range_time(time_start, time_end, aprox=True)[0]\n",
    "\n",
    "    return natus_data\n",
    "\n",
    "\n",
    "def convert_ECoG_BP(natus_data, BP_ELECS):\n",
    "    natus_data['data'] = (natus_data['data'][:, BP_ELECS['Anode'].values] -\n",
    "                          natus_data['data'][:, BP_ELECS['Cathode'].values])\n",
    "\n",
    "    return natus_data\n",
    "\n",
    "\n",
    "def half_life(duration, fs_state):\n",
    "    samples = duration / fs_state\n",
    "    return np.exp(-(1/samples)*np.log(2))\n",
    "\n",
    "\n",
    "def plot_time_stacked(sig, fs, wsize=10, color='k', labels=None, zscore=True, scale=3, ax=None):\n",
    "    \"\"\"\n",
    "    Plot of the normalized signal in a stacked montage.\n",
    "    Parameters\n",
    "    ----------\n",
    "    sig: np.ndarray, shape: [n_sample, n_ch]\n",
    "        Time series signal.\n",
    "    fs: float\n",
    "        Sampling frequency of the signal (in Hz)\n",
    "    wsize: float\n",
    "        Window size in seconds.\n",
    "    color: str\n",
    "        Color of the plot lines.\n",
    "    labels: array-like, len(n_ch)\n",
    "        Labels corresponding to the channel names.\n",
    "    scale: float, default=3.0\n",
    "        Standard deviations of signal fluctuation by which the montage is\n",
    "        vertically spaced for each channel.\n",
    "    ax: matplotlib axis\n",
    "        For updating the plot post-hoc.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    sig = sig[...]\n",
    "    n_s, n_ch = sig.shape\n",
    "    ts = np.arange(0, n_s) / fs\n",
    "    if labels is None:\n",
    "        labels = ['Ch{}'.format(ix + 1) for ix in range(n_ch)]\n",
    "\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(24, 12))\n",
    "        ax = plt.subplot(111)\n",
    "\n",
    "    if zscore:\n",
    "        sig_Z = (sig - np.nanmean(sig, axis=0)) / np.nanstd(sig, axis=0)\n",
    "    else:\n",
    "        sig_Z = sig\n",
    "\n",
    "    offset = np.arange(n_ch) * scale\n",
    "\n",
    "    for ch, sig_ch in enumerate(sig_Z.T):\n",
    "        ax.plot(ts, sig_ch + offset[ch], color=color, alpha=0.5, linewidth=0.5)\n",
    "\n",
    "        ax.hlines(offset[ch], ts[0], ts[-1], color='k', alpha=1.0, linewidth=0.2)\n",
    "\n",
    "    ax.set_yticks(offset)\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    ax.set_xlim([ts[0], ts[0] + wsize])\n",
    "    ax.set_ylim([np.min(offset) - scale, np.max(offset) + scale])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def do_fitting(foo, freqs, spectrum, freq_range):\n",
    "    foo.add_data(freqs, spectrum, freq_range)\n",
    "    aperiodic_params_ = foo._robust_ap_fit(freqs, spectrum)\n",
    "    ap_fit = gen_aperiodic(freqs, aperiodic_params_)\n",
    "    r_val = np.corrcoef(spectrum, ap_fit)\n",
    "    return r_val[0][1] ** 2\n",
    "\n",
    "\n",
    "def do_fittings(foo, freqs, spectra, freq_range):\n",
    "    r_sq = []\n",
    "    for spectrum in spectra:\n",
    "        r_sq.append(do_fitting(foo, freqs, spectrum, freq_range))\n",
    "\n",
    "    return r_sq\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup #\n",
    "SUBJECT_ID = 'EC212'\n",
    "win_size = 1\n",
    "plot_window = True\n",
    "a_out_dir = pathlib.Path(f\"/home/anthonyfong/ProjectData/EpilepsySpikeDetection/{SUBJECT_ID}/artifact\")\n",
    "a_out_r_path = a_out_dir.joinpath(f\"R2_{win_size}seconds.h5\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load Electrode Montage #\n",
    "IMG_PATH = pathlib.Path('/common/imaging/subjects/')\n",
    "IMAGING_PATH = IMG_PATH.joinpath(SUBJECT_ID, 'elecs', 'clinical_TDT_elecs_all.mat')\n",
    "IMAGING = loadmat(IMAGING_PATH.as_posix(), squeeze_me=True)\n",
    "\n",
    "# Generate Bipolar Montage\n",
    "BP_ELECS_ALL = make_bipolar_elecs_all(IMAGING['eleclabels'], IMAGING['elecmatrix'])\n",
    "\n",
    "# Remove common bad labels\n",
    "BAD_EL = ['EKG', 'REF', 'Reference']\n",
    "BP_ELECS_ALL = BP_ELECS_ALL.loc[~BP_ELECS_ALL['Lead'].isin(BAD_EL)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load Study #\n",
    "STUDY_PATH = pathlib.Path('/common/xltek/subjects')\n",
    "study_frame = hdframes.XLTEKStudyFrame(s_id=SUBJECT_ID, studies_path=STUDY_PATH)\n",
    "\n",
    "T0 = (study_frame.get_start() + datetime.timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "T0 = T0 + datetime.timedelta(seconds=0)\n",
    "t0 = T0\n",
    "tF = T0 + datetime.timedelta(minutes=1)\n",
    "tD = datetime.timedelta(seconds=win_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Artifact Stuff\n",
    "fg = FOOOFGroup(peak_width_limits=[4, 8], min_peak_height=0.05, max_n_peaks=5, verbose=True)\n",
    "artifact_tracking = {\n",
    "    'Timestamp': {'Start': [], 'End': [], 'Elapsed': []},  # General timestamp info for each window chunk\n",
    "\n",
    "    \"Timing\": {\"Spectra\": [], \"fooof\": []},\n",
    "\n",
    "    \"spectra\": {\"r_squared\": []},\n",
    "\n",
    "    'channel_artifact': {'otl_state': [],  # Vector of historical state-values per channel\n",
    "                         'otl_decay': half_life(5, 0.5),\n",
    "                         # Duration that a single artifact occurrence should persist\n",
    "                         'otl_thresh': 1.5,\n",
    "                         # Threshold for determining whether a channel artifact has occurred\n",
    "                         'is_bad': []},  # Final binary designation of which channels are bad\n",
    "\n",
    "    'population_artifact': {'otl_state': [],  # Vector of historical state-values for the entire population\n",
    "                            'otl_decay': half_life(60, 0.5),\n",
    "                            # Duration that a single artifact occurrence should persist\n",
    "                            'otl_welford': None,\n",
    "                            # Threshold for determining whether a population artifact has occurred\n",
    "                            'otl_thresh': 10,\n",
    "                            # Threshold for determining whether a channel artifact has occurred\n",
    "                            'is_bad': []}  # Final binary designation of whether a channel is bad\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Iterate over windows of the study frame\n",
    "while t0 <= (tF - tD):\n",
    "    t0 += tD\n",
    "    t1 = t0 + tD\n",
    "\n",
    "    # print('\\r{} -- {}'.format(t0, t1), end='')\n",
    "\n",
    "    try:\n",
    "        ### Try to grab current frame\n",
    "        raw_ecog = get_ECoG_sample(study_frame, t0, t1)\n",
    "        raw_ecog = convert_ECoG_BP(raw_ecog, BP_ELECS_ALL)\n",
    "        if len(raw_ecog['data']) < (raw_ecog['fs'] * win_size):\n",
    "            raise Exception('Unable to grab full ECoG window.')\n",
    "\n",
    "        # Spectra Rejection\n",
    "        s_start = time.perf_counter()\n",
    "        f_transform = np.fft.rfft(raw_ecog[\"data\"], axis=0)\n",
    "        spectra = np.square(np.abs(f_transform))\n",
    "        s_timing = time.perf_counter() - s_start\n",
    "\n",
    "        freqs = np.linspace(0, 1024.0/2, spectra.shape[0])\n",
    "\n",
    "        f_start = time.perf_counter()\n",
    "        # pr = cProfile.Profile()\n",
    "        # pr.enable()\n",
    "\n",
    "        fg.fit(freqs=freqs, power_spectra=spectra.T, freq_range=[3, 150], n_jobs=1)\n",
    "\n",
    "        # pr.disable()\n",
    "        # s = io.StringIO()\n",
    "        # sortby = pstats.SortKey.TIME\n",
    "        # ps = StatsMicro(pr, stream=s).sort_stats(sortby)\n",
    "        # ps.print_stats()\n",
    "        # print(s.getvalue())\n",
    "        f_timing = time.perf_counter() - f_start\n",
    "\n",
    "        r_squared_vector = np.array([c[2] for c in fg.group_results], ndmin=2)\n",
    "\n",
    "        all = artifact_tracking[\"spectra\"][\"r_squared\"]\n",
    "        artifact_tracking[\"spectra\"][\"r_squared\"].append(r_squared_vector)\n",
    "\n",
    "        artifact_tracking[\"Timing\"][\"Spectra\"].append(s_timing)\n",
    "        artifact_tracking[\"Timing\"][\"fooof\"].append(f_timing)\n",
    "\n",
    "\n",
    "        if plot_window:\n",
    "            # Plot\n",
    "            plot_time_stacked(raw_ecog[\"data\"], 1024)\n",
    "            fig1 = plt.figure()\n",
    "            ax1 = fig1.add_subplot(111)\n",
    "            ax1.plot(r_squared_vector.T, linestyle=\"\", marker=\"o\")\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    except Exception as E:\n",
    "        print(E)\n",
    "\n",
    "    #### Update the artifact tracking dictionary\n",
    "    artifact_tracking['Timestamp']['Start'].append(t0)\n",
    "    artifact_tracking['Timestamp']['End'].append(t1)\n",
    "    artifact_tracking['Timestamp']['Elapsed'].append((t0 - T0).total_seconds())\n",
    "\n",
    "all_r_squared = np.concatenate(artifact_tracking[\"spectra\"][\"r_squared\"], axis=0)\n",
    "timestamps = np.array([dt.timestamp() for dt in artifact_tracking[\"Timestamp\"][\"Start\"]])\n",
    "\n",
    "# Save Data\n",
    "with R2HDF5(file=a_out_r_path, create=True, build=True) as s_file:\n",
    "    s_file[\"data\"].require(data=all_r_squared, sample_rate=1.0 / win_size, start=artifact_tracking[\"Timestamp\"][\"Start\"][0])\n",
    "    R2_timeseries = s_file[\"data\"]\n",
    "    time_axis = R2_timeseries.time_axis\n",
    "    time_axis[...] = timestamps\n",
    "\n",
    "# Load Data\n",
    "with R2HDF5(file=a_out_r_path, load=True) as l_file:\n",
    "    R2_timeseries = l_file[\"data\"]\n",
    "    time_axis = R2_timeseries.time_axis\n",
    "    fig1 = plt.figure(figsize=(10, 10), dpi=320)\n",
    "    ax1 = fig1.add_subplot()\n",
    "    ax1.imshow(R2_timeseries[...].T,\n",
    "               vmin=0,\n",
    "               vmax=1,\n",
    "               aspect=\"auto\",\n",
    "               cmap='Reds')\n",
    "    ax1.set_xlabel('Windows')\n",
    "    ax1.set_ylabel('Channels')\n",
    "    ax1.set_title('Channel-wise R2 Values')\n",
    "    ax1.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}